# ML-Model-Serving-Platform
A fast and scalable platform to serve machine learning models, built with NVIDIA Triton Inference Server and hosted on AWS.
